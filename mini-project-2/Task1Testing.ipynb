{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, AveragePooling2D\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from keras.applications.inception_v3 import preprocess_input as incv3_preprocess_input\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and feature extraction using Pretrained Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (299,299,3)\n",
    "\n",
    "def create_model_incv3():\n",
    "    tf_input = Input(shape=input_shape)\n",
    "    model = InceptionV3(input_tensor=tf_input, weights='imagenet', include_top=False)\n",
    "    output_pooled = AveragePooling2D((8, 8), strides=(8, 8))(model.output)\n",
    "    return Model(model.input, output_pooled)\n",
    "\n",
    "create_model = create_model_incv3\n",
    "\n",
    "batch_of_images_placeholder = tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.uint8)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "tf_resize_op = lambda images: tf.image.resize(tf.cast(images, tf.float32), input_shape[:2])\n",
    "\n",
    "preprocess_input = incv3_preprocess_input\n",
    "\n",
    "# Define generator\n",
    "def data_generator(data, labels=None):\n",
    "    def generator():\n",
    "        n = data.shape[0]\n",
    "        start = 0\n",
    "        while start < n:\n",
    "            end = min(start + batch_size, n)\n",
    "            batch_of_images = data[start:end]\n",
    "            batch_of_images_resized = tf_resize_op(batch_of_images)\n",
    "            batch_of_images_preprocessed = preprocess_input(batch_of_images_resized)\n",
    "            if labels is not None:\n",
    "                batch_of_labels = labels[start:end]\n",
    "            else:\n",
    "                # Create dummy labels as a placeholder when no labels are provided\n",
    "                batch_of_labels = np.zeros((batch_of_images_preprocessed.shape[0],))\n",
    "            yield (batch_of_images_preprocessed, batch_of_labels)\n",
    "            start += batch_size\n",
    "    return generator\n",
    "\n",
    "model_extract = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4308/2693620957.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t_train_1 = torch.load('dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
      "/tmp/ipykernel_4308/2693620957.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t_eval_1 = torch.load('dataset/part_one_dataset/eval_data/1_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 830ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 802ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4308/2693620957.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t_train = torch.load(f'dataset/part_one_dataset/train_data/{I}_train_data.tar.pth')\n",
      "/tmp/ipykernel_4308/2693620957.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  t_eval = torch.load(f'dataset/part_one_dataset/eval_data/{I}_eval_data.tar.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 859ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 791ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 803ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 813ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 848ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 850ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 862ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 807ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 815ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 884ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 834ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 846ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 847ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 789ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 833ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 811ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 795ms/step\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 811ms/step\n"
     ]
    }
   ],
   "source": [
    "t_train_1 = torch.load('dataset/part_one_dataset/train_data/1_train_data.tar.pth')\n",
    "x_train_1, y_train_1 = t_train_1['data'], t_train_1['targets'] # both numpy.ndarray\n",
    "t_eval_1 = torch.load('dataset/part_one_dataset/eval_data/1_eval_data.tar.pth')\n",
    "x_eval_1, y_eval_1 = t_eval_1['data'], t_eval_1['targets'] # both numpy.ndarray\n",
    "\n",
    "x_train_1 = np.array(x_train_1)\n",
    "x_eval_1 = np.array(x_eval_1)\n",
    "y_train_1 = np.array(y_train_1)\n",
    "y_eval_1 = np.array(y_eval_1)\n",
    "\n",
    "n_training = x_train_1.shape[0]\n",
    "n_evaling = y_eval_1.shape[0]\n",
    "\n",
    "y_train_1 = y_train_1.flatten()\n",
    "y_eval_1  = y_eval_1.flatten()\n",
    "\n",
    "data_train_gen = data_generator(x_train_1, y_train_1)()\n",
    "ftrs_training = model_extract.predict(data_train_gen, steps=math.ceil(n_training/batch_size), verbose=1)\n",
    "\n",
    "data_eval_gen = data_generator(x_eval_1, y_eval_1)()\n",
    "ftrs_evaling = model_extract.predict(data_eval_gen, steps=math.ceil(n_evaling/batch_size), verbose=1)\n",
    "\n",
    "x_train_extracted_1 = np.array( [ftrs_training[i].flatten() for i in range(n_training)] )\n",
    "x_eval_extracted_1  = np.array( [ftrs_evaling[i].flatten()  for i in range(n_evaling )] )\n",
    "\n",
    "def extract_features(I, model_extract, data_generator, batch_size):\n",
    "    # Load the training and evaluation datasets using `I`\n",
    "    t_train = torch.load(f'dataset/part_one_dataset/train_data/{I}_train_data.tar.pth')\n",
    "    x_train = t_train['data']  # numpy.ndarray\n",
    "    t_eval = torch.load(f'dataset/part_one_dataset/eval_data/{I}_eval_data.tar.pth')\n",
    "    x_eval, y_eval = t_eval['data'], t_eval['targets']  # numpy.ndarray\n",
    "\n",
    "    # Convert data to numpy arrays\n",
    "    x_train = np.array(x_train)\n",
    "    x_eval = np.array(x_eval)\n",
    "    y_eval = np.array(y_eval).flatten()  # Flatten y_eval for consistency\n",
    "\n",
    "    # Get number of samples in training and evaluation sets\n",
    "    n_training = x_train.shape[0]\n",
    "    n_evaling = y_eval.shape[0]\n",
    "\n",
    "    # Generate data for model extraction\n",
    "    data_train_gen = data_generator(x_train, None)()\n",
    "    ftrs_training = model_extract.predict(data_train_gen, steps=math.ceil(n_training / batch_size), verbose=1)\n",
    "\n",
    "    data_eval_gen = data_generator(x_eval, None)()\n",
    "    ftrs_evaling = model_extract.predict(data_eval_gen, steps=math.ceil(n_evaling / batch_size), verbose=1)\n",
    "\n",
    "    # Extract features by flattening predictions\n",
    "    x_train_extracted = np.array([ftrs_training[i].flatten() for i in range(n_training)])\n",
    "    x_eval_extracted = np.array([ftrs_evaling[i].flatten() for i in range(n_evaling)])\n",
    "\n",
    "    return x_train_extracted, x_eval_extracted, y_eval\n",
    "\n",
    "for I in range(2,11):\n",
    "    globals()[f\"x_train_extracted_{I}\"], globals()[f\"x_eval_extracted_{I}\"], globals()[f\"y_eval_{I}\"] = extract_features(\n",
    "        I=I,\n",
    "        model_extract=model_extract,\n",
    "        data_generator=data_generator,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving extracted features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    feature = eval(f\"x_train_extracted_{i}\")\n",
    "    folder_path = \"extracted_features\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_name = f\"x_train_extracted_{i}.npy\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    np.save(file_path, feature)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    feature = eval(f\"x_eval_extracted_{i}\")\n",
    "    folder_path = \"extracted_features\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_name = f\"x_eval_extracted_{i}.npy\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    np.save(file_path, feature)\n",
    "\n",
    "for i in range(1, 2):\n",
    "    feature = eval(f\"y_train_{i}\")\n",
    "    folder_path = \"extracted_features\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_name = f\"y_train_{i}.npy\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    np.save(file_path, feature)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    feature = eval(f\"y_eval_{i}\")\n",
    "    folder_path = \"extracted_features\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    file_name = f\"y_eval_{i}.npy\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    np.save(file_path, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Saved Extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    globals()[f'x_eval_extracted_{i}'] = np.load(f'extracted_features/x_eval_extracted_{i}.npy')\n",
    "    globals()[f'x_train_extracted_{i}'] = np.load(f'extracted_features/x_train_extracted_{i}.npy')\n",
    "    globals()[f'y_eval_{i}'] = np.load(f'extracted_features/y_eval_{i}.npy')\n",
    "\n",
    "y_train_1 = np.load('y_train_1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Classifier Continual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeClassifierContinual:\n",
    "    def __init__(self, n_classes, n_features, alpha=0.5):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_features = n_features\n",
    "        self.means = np.zeros((n_classes, n_features))\n",
    "        self.covariances = np.array([np.eye(n_features) for _ in range(n_classes)])\n",
    "        self.alpha = alpha  # Regularization weight\n",
    "\n",
    "    def fit(self, X_train, y_train, prev_means=None, prev_covariances=None):\n",
    "        new_means = np.zeros((self.n_classes, self.n_features))\n",
    "        new_covariances = np.array([np.eye(self.n_features) for _ in range(self.n_classes)])\n",
    "\n",
    "        # Calculate Gaussian parameters for current data\n",
    "        for c in range(self.n_classes):\n",
    "            class_samples = X_train[y_train == c]\n",
    "            if len(class_samples) > 0:\n",
    "                new_means[c] = np.mean(class_samples, axis=0)\n",
    "                if len(class_samples) > 1:\n",
    "                    new_covariances[c] = np.cov(class_samples, rowvar=False) + 1e-6 * np.eye(self.n_features)\n",
    "\n",
    "        # Regularize means and covariances with the previous model's parameters\n",
    "        if prev_means is not None and prev_covariances is not None:\n",
    "            self.means = self.alpha * prev_means + (1 - self.alpha) * new_means\n",
    "            self.covariances = self.alpha * prev_covariances + (1 - self.alpha) * new_covariances\n",
    "        else:\n",
    "            self.means = new_means\n",
    "            self.covariances = new_covariances\n",
    "\n",
    "    def generate_replay_data(self, num_samples_per_class=50):\n",
    "        # Generate synthetic data based on current Gaussian parameters\n",
    "        replay_data = []\n",
    "        replay_labels = []\n",
    "        for c in range(self.n_classes):\n",
    "            samples = np.random.multivariate_normal(self.means[c], self.covariances[c], num_samples_per_class)\n",
    "            replay_data.append(samples)\n",
    "            replay_labels.append(np.full(num_samples_per_class, c))\n",
    "        return np.vstack(replay_data), np.concatenate(replay_labels)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Calculate log probabilities for each class\n",
    "        log_probs = np.zeros((X.shape[0], self.n_classes))\n",
    "        for c in range(self.n_classes):\n",
    "            distribution = multivariate_normal(mean=self.means[c], cov=self.covariances[c])\n",
    "            log_probs[:, c] = distribution.logpdf(X)\n",
    "\n",
    "        # Assign each sample to the class with the highest log probability\n",
    "        predictions = np.argmax(log_probs, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca_components = 40  # Change this to any number of components\n",
    "\n",
    "# Initialize PCA with the chosen number of components\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "# Apply standardization and PCA to D1\n",
    "x_train_1_scaled = scaler.fit_transform(x_train_extracted_1)\n",
    "x_train_1_pca = pca.fit_transform(x_train_1_scaled)\n",
    "\n",
    "# Initialize the first model for D1 with dynamic n_features\n",
    "n_classes = np.unique(y_train_1).size\n",
    "model_list = [GenerativeClassifierContinual(n_classes, n_features=pca_components)]\n",
    "model_list[0].fit(x_train_1_pca, y_train_1)\n",
    "\n",
    "# Continual learning with Gaussian class-conditionals, prototype regularization, and generative replay\n",
    "for i in range(2, 11):\n",
    "    # Standardize and apply PCA to the current dataset\n",
    "    x_train_scaled = scaler.transform(globals()[f'x_train_extracted_{i}'])\n",
    "    x_train_pca = pca.transform(x_train_scaled)\n",
    "\n",
    "    # Generate replay data using the previous model\n",
    "    replay_data, replay_labels = model_list[-1].generate_replay_data(num_samples_per_class=50)\n",
    "\n",
    "    # Combine replay data with current data\n",
    "    x_combined = np.vstack([x_train_pca, replay_data])\n",
    "    y_combined = np.concatenate([model_list[-1].predict(x_train_pca), replay_labels])\n",
    "\n",
    "    # Train a new model with regularized Gaussian parameters\n",
    "    model = GenerativeClassifierContinual(n_classes, n_features=pca_components, alpha=0.7)\n",
    "    model.fit(x_combined, y_combined,\n",
    "              prev_means=model_list[-1].means, prev_covariances=model_list[-1].covariances)\n",
    "\n",
    "    # Append the new model to the model list\n",
    "    model_list.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy checking of different Models with different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Matrix:\n",
      "          Eval Dataset 1  Eval Dataset 2  Eval Dataset 3  Eval Dataset 4  \\\n",
      "Model 1            80.52           81.04           80.00           80.04   \n",
      "Model 2            80.40           81.88           80.44           80.12   \n",
      "Model 3            80.68           81.16           79.92           79.32   \n",
      "Model 4            80.44           80.60           79.68           79.16   \n",
      "Model 5            80.32           80.64           79.52           78.92   \n",
      "Model 6            80.24           80.16           78.76           78.72   \n",
      "Model 7            79.76           79.92           78.72           78.64   \n",
      "Model 8            79.32           79.40           78.32           78.56   \n",
      "Model 9            78.44           78.84           77.52           78.00   \n",
      "Model 10           78.28           78.44           77.16           77.72   \n",
      "\n",
      "          Eval Dataset 5  Eval Dataset 6  Eval Dataset 7  Eval Dataset 8  \\\n",
      "Model 1            79.16           80.48           80.32           80.80   \n",
      "Model 2            79.32           80.56           80.16           80.76   \n",
      "Model 3            79.72           80.28           79.84           80.52   \n",
      "Model 4            79.56           79.80           79.00           80.28   \n",
      "Model 5            79.20           79.76           79.04           80.52   \n",
      "Model 6            79.04           79.56           78.64           80.04   \n",
      "Model 7            78.44           79.32           78.72           79.76   \n",
      "Model 8            78.36           78.72           77.88           79.44   \n",
      "Model 9            78.20           78.20           77.72           79.16   \n",
      "Model 10           77.72           78.00           77.36           78.88   \n",
      "\n",
      "          Eval Dataset 9  Eval Dataset 10  \n",
      "Model 1            78.44            79.68  \n",
      "Model 2            78.64            79.32  \n",
      "Model 3            79.20            79.68  \n",
      "Model 4            79.04            79.76  \n",
      "Model 5            78.80            79.28  \n",
      "Model 6            78.60            79.32  \n",
      "Model 7            78.44            78.96  \n",
      "Model 8            77.60            78.64  \n",
      "Model 9            77.24            78.56  \n",
      "Model 10           76.92            78.12  \n"
     ]
    }
   ],
   "source": [
    "accuracy_matrix = np.zeros((10, 10))\n",
    "\n",
    "for i, model in enumerate(model_list):\n",
    "    for j in range(10):\n",
    "        # Standardize and apply PCA to the evaluation dataset\n",
    "        x_eval_scaled = scaler.transform(globals()[f'x_eval_extracted_{j+1}'])\n",
    "        x_eval_pca = pca.transform(x_eval_scaled)\n",
    "\n",
    "        eval_labels = globals()[f'y_eval_{j+1}']\n",
    "        accuracy_matrix[i, j] = model.score(x_eval_pca, eval_labels)*100\n",
    "\n",
    "print(\"Accuracy Matrix:\")\n",
    "\n",
    "accuracy_matrix = pd.DataFrame(\n",
    "    accuracy_matrix,\n",
    "    index=[f\"Model {i+1}\" for i in range(10)],\n",
    "    columns=[f\"Eval Dataset {j+1}\" for j in range(10)]\n",
    ")\n",
    "\n",
    "print(accuracy_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the models and transformation for next task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca.joblib']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model_list, scaler, and pca\n",
    "joblib.dump(model_list, 'model_list.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(pca, 'pca.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
